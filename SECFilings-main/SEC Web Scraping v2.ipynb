{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import bs4\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check4nextpage returns True or False\n",
    "\n",
    "def check4nextpage(URL):\n",
    "    \n",
    "    res = requests.get(URL)\n",
    "    soup = bs4.BeautifulSoup(res.text,'html.parser')\n",
    "    nextButton = soup.find_all('input', type = 'button', value = 'Next 100', limit = 1)\n",
    "    prevButton = soup.find_all('input', type = 'button', value = 'Previous 100', limit = 1)\n",
    "    \n",
    "    if nextButton:\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_descriptions pulls all the 10-Ks and 10-Qs on a certain page\n",
    "\n",
    "def get_descriptions(URL):\n",
    "    someRes = requests.get(URL)\n",
    "    someSoup = bs4.BeautifulSoup(someRes.text, 'html.parser')\n",
    "\n",
    "    descriptions = []\n",
    "    \n",
    "    for i in someSoup.find_all('tr'):\n",
    "        for j in i.find_all('a', attrs = {'href' : re.compile('Archives')}):\n",
    "            if '/A' in i.text:\n",
    "                break\n",
    "            if '10-Q' in i.text or '10-K' in i.text:\n",
    "                descriptions.append(i.text)\n",
    "                \n",
    "        # Clean Up\n",
    "    filingType = []\n",
    "    for i in descriptions:\n",
    "        if '10-Q' in i:\n",
    "            filingType.append('10-Q')\n",
    "        if '10-K' in i:\n",
    "            filingType.append('10-K')\n",
    "    \n",
    "    return filingType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_links pulls all the links to the 10-Ks and 10-Qs on a certain page\n",
    "\n",
    "def get_links(URL):\n",
    "    someRes = requests.get(URL)\n",
    "    someSoup = bs4.BeautifulSoup(someRes.text,'html.parser')\n",
    "    \n",
    "    links = []\n",
    "    for i in someSoup.find_all('tr'):\n",
    "        for j in i.find_all('a', attrs = {'href' : re.compile('Archives')}):\n",
    "            if '/A' in i.text:\n",
    "                break\n",
    "            if '10-Q' in i.text or '10-K' in i.text:\n",
    "                links.append(j.get('href'))\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_generator(tickersymbol):\n",
    "    file = open('ticker.txt','r')\n",
    "    lines = file.readlines()\n",
    "\n",
    "    d = {}\n",
    "    for i in lines: \n",
    "        (key, val) = i.split()\n",
    "        d[(key)] = val\n",
    "    \n",
    "    CIK = d[str(tickersymbol.lower())]\n",
    "    \n",
    "    while len(CIK) <= 10:\n",
    "        CIK = '0' + CIK\n",
    "    \n",
    "    index = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=#REPLACEME#&owner=exclude&count=100'\n",
    "    URL = index.replace('#REPLACEME#',CIK)\n",
    "    \n",
    "    return URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type in a Ticker symbolaapl\n"
     ]
    }
   ],
   "source": [
    "ticker = input('Type in a Ticker symbol ')\n",
    "\n",
    "URL = link_generator(ticker)\n",
    "\n",
    "URL_og = URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [URL] # initiates a list pages with the original URL\n",
    "n = 100 # initiates a variable that will be used to navigate the following pages\n",
    "\n",
    "for i in pages: # uses check4nextpage to create a list of the all the links that exist for a certain name\n",
    "    \n",
    "    while check4nextpage(URL) == True:\n",
    "        newURL = URL_og + '&start=' + str(n)\n",
    "        URL = newURL\n",
    "        n += 100\n",
    "        pages.append(newURL)\n",
    "        \n",
    "    if check4nextpage(URL) == False:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filings = []\n",
    "for i in pages: # iterates through all the pages to pull the filings types\n",
    "    filings.extend(get_descriptions(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for i in pages: # iterates through all the pages to pull the links the filing types\n",
    "    links.extend(get_links(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filings</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-K</td>\n",
       "      <td>/Archives/edgar/data/320193/000032019320000096...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>/Archives/edgar/data/320193/000032019320000062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>/Archives/edgar/data/320193/000032019320000052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>/Archives/edgar/data/320193/000032019320000010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-K</td>\n",
       "      <td>/Archives/edgar/data/320193/000032019319000119...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>/Archives/edgar/data/320193/0000320193-95-0000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>/Archives/edgar/data/320193/0000320193-95-0000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>10-K</td>\n",
       "      <td>/Archives/edgar/data/320193/0000320193-94-0000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>/Archives/edgar/data/320193/0000320193-94-0000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>/Archives/edgar/data/320193/0000320193-94-0000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Filings                                              Links\n",
       "0      10-K  /Archives/edgar/data/320193/000032019320000096...\n",
       "1      10-Q  /Archives/edgar/data/320193/000032019320000062...\n",
       "2      10-Q  /Archives/edgar/data/320193/000032019320000052...\n",
       "3      10-Q  /Archives/edgar/data/320193/000032019320000010...\n",
       "4      10-K  /Archives/edgar/data/320193/000032019319000119...\n",
       "..      ...                                                ...\n",
       "104    10-Q  /Archives/edgar/data/320193/0000320193-95-0000...\n",
       "105    10-Q  /Archives/edgar/data/320193/0000320193-95-0000...\n",
       "106    10-K  /Archives/edgar/data/320193/0000320193-94-0000...\n",
       "107    10-Q  /Archives/edgar/data/320193/0000320193-94-0000...\n",
       "108    10-Q  /Archives/edgar/data/320193/0000320193-94-0000...\n",
       "\n",
       "[109 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Filings': filings, 'Links': links})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is still a work in progress\n",
    "\n",
    "root = 'https://www.sec.gov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filingURL = []\n",
    "\n",
    "for i in links: # create a list of all the filingURLs\n",
    "    filingURL.append(root + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdirectlink(URL):\n",
    "    \n",
    "    someRes = requests.get(URL)\n",
    "    someSoup = bs4.BeautifulSoup(someRes.text, 'html.parser')\n",
    "    \n",
    "    for i in someSoup.find_all('table', class_ = 'tableFile'):\n",
    "        for j in i.find_all('a', attrs = {'href':re.compile('Archives')}, limit = 1):\n",
    "            return (j.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "directlinks = []\n",
    "\n",
    "for i in filingURL:\n",
    "    directlinks.append(getdirectlink(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalURLs = []\n",
    "\n",
    "for i in directlinks[0:28]:\n",
    "    someURL = root + i\n",
    "    if '/ix?doc=/' in someURL:\n",
    "        someURL = someURL.replace('/ix?doc=','')\n",
    "    finalURLs.append(someURL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = str(ticker.upper()) +'_URL_List'\n",
    "\n",
    "f = open(filename,'x')\n",
    "\n",
    "with open(filename,'w') as filehandle:\n",
    "    filehandle.writelines(\"%s\\n\" % place for place in finalURLs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
